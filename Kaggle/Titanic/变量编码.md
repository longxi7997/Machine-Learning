通常，在数据清洗完成，输入模型之前，需要对分类变量进行编码。目前我所知道的编码方式有以下几种：
One-hot 、 Dummy 、Ordinal 、Binary等 

编码：树模型通常不需要进行编码（进行One-hot增加了维度，相当于人为的增加了树的深度），只有计算距离的模型才需要进行编码。One-hot编码就是为了防止无序的变量取值在编码之后变得有序。

## One-hot VS Dummy:
**参考：**<br>
- [https://mp.weixin.qq.com/s?__biz=MzI3NTA0MzM1OQ==&mid=2651615354&idx=1&sn=b74b1d526746b401947ff98b389e797f&chksm=f0f2150ac7859c1c2ebd41f080ff40b034443118d0c9d27a3964a59b7ad8c8cfa232346d8262&mpshare=1&scene=1&srcid=0527OgF5sinRLzc8j2qdc2Xm#rd](https://mp.weixin.qq.com/s?__biz=MzI3NTA0MzM1OQ==&mid=2651615354&idx=1&sn=b74b1d526746b401947ff98b389e797f&chksm=f0f2150ac7859c1c2ebd41f080ff40b034443118d0c9d27a3964a59b7ad8c8cfa232346d8262&mpshare=1&scene=1&srcid=0527OgF5sinRLzc8j2qdc2Xm#rd)<br>
-[http://www.willmcginnis.com/2015/11/29/beyond-one-hot-an-exploration-of-categorical-variables/](http://www.willmcginnis.com/2015/11/29/beyond-one-hot-an-exploration-of-categorical-variables/) <br> 
- [http://www.statsmodels.org/devel/contrasts.html](http://www.statsmodels.org/devel/contrasts.html) <br>
- [http://cml.ics.uci.edu/](http://cml.ics.uci.edu/)

----------

One-hot将每个变量的每个取值展成一个维度，可能导致维度爆炸(好处也是人为的扩充了维度，且相当于进行了一次kernel的映射，可能可以解决线性不可分问题？),如果训练集的量不变，过高的维度可能不利于模型训练<br>

1. 此时可以做PCA进行降维
2. ordinal coding : 但会人为引入无关类别取值的顺序
2. 可以先对变量的取值进行聚类，再进行编码
3. 正则化
4. 但这种方式最大的问题在于，One-hot 编码会导致多重线性问题，使方程有多组解，进而造成模型不稳定；或者得到的权值因子不对（即，权值较大的变量，实际对结果的影响并不大，还是因为受到多组解的影响）。
5. Dummy可以通过减少一维（k-1维）对变量取值进行编码，避免这个问题。但这样，当测试集中出现了训练集中没有出现过的取值是，无法处理。One-hot可以全取0来应对这种情况。
6. 此时就可以另外一种方式来理解正则化：因为One-hot有多重共线的问题，因而会有很多组解，正则化就是为了抑制解空间。 


----------

## 类别型变量编码方式汇总
（参考： [http://www.willmcginnis.com/2015/11/29/beyond-one-hot-an-exploration-of-categorical-variables/](http://www.willmcginnis.com/2015/11/29/beyond-one-hot-an-exploration-of-categorical-variables/)）

1. Ordinal:每种类型取值给一个值（1，2，3...），相当于人为的引入了类别取值之间本不存在的顺序关系。但是，有一些变量，比如年龄（幼儿、青年、中年、老年）这种，有序的类别，可以试试这种方式。
2. One-hot：不再赘述
3. Dummy（Treament）:![](https://i.imgur.com/PgGN8kS.png)（[https://stats.stackexchange.com/questions/224051/one-hot-vs-dummy-encoding-in-scikit-learn](https://stats.stackexchange.com/questions/224051/one-hot-vs-dummy-encoding-in-scikit-learn)）
3. Binary:先进行 Ordinal 编码，在将每个取值二进制化，再把二进制串的每一位，当成一个新的维度。我认为这种方法是 Ordinal 和 Onh-hot的一个折中。相比于Ordinal，Binary将类别顺序打乱了；但相比于One-hot，Binary的维度又降低了。
4. Sum(Deviation)：
5. Backward Difference Coding:
6. Helmert Coding:
7. Orthogonal Polynomical Coding:
8. User-defined Coding:

各种编码在UCI公共数据集上的效果：
![](https://i.imgur.com/QAp27hG.png)

![](https://i.imgur.com/ArLrJAw.png)

![](https://i.imgur.com/k8WBgOX.png)

从上面的结果看起来看起来，Ordinal的效果一直比较差；Binary Coding的效果还不错，One-hot时好时坏。

----------

## sciit-learn 中的特征二值化方式
直接引用：[https://mp.weixin.qq.com/s?__biz=MzI3NTA0MzM1OQ==&mid=2651615335&idx=1&sn=d3910d6b12121e040a54f4c73bde4202&mpshare=1&scene=1&srcid=05276w2L1RFZx8t6BtsprqO7#rd](https://mp.weixin.qq.com/s?__biz=MzI3NTA0MzM1OQ==&mid=2651615335&idx=1&sn=d3910d6b12121e040a54f4c73bde4202&mpshare=1&scene=1&srcid=05276w2L1RFZx8t6BtsprqO7#rd)



----------


## 多重共线问题：

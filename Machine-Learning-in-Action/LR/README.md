# 逻辑回归 #
----------
## 用于解决二分类问题，错误率的评价指标
#### 1. 错误率与精度: 
错误率：$$ {1\over m} \sum_{i=1}^m f(x _i) \neq y _i $$

精度：$$ {1\over m} \sum_{i=1}^m f(x _i) = y _i $$

如果是概率密度分布，则考虑 概率*概率分布函数（即将累和变成积分）。假设数据分布D和概率密度函数p(*)，则
错误率：
$$ \int _{x \sim D}  ( f(x) \neq y )* p(x)  dx $$

#### 2. 查全率、查准率、F1：<br>
查准率：<br>
$$ 预测为第i类中预测对的\over 预测为第i类的总数  $$
查全率：
$$  预测为第i类中预测对的 \over 第i类的总数  $$

查全率与查准率曲线：P-R曲线 <br>
P-R曲线的面积越大越好；<br>
当查全率=查准率时，为平衡点，平衡点越靠近外面（右上角）越好。
F1：查全率与查准率的调和平均数，更关注不均匀性，关注二者中较小的（继续改进可以用加权的调和平均数）：
$$ {1 \over F1} = {1\over 2}*( { {1\over 查准率} + {1\over 查全率} } ) $$
对于多分类问题：
先求出混淆矩阵的多个查全率、查准率、F1，然后求平均，即为宏查准率、宏查全率、宏F1；<br>
也可先求真正例、假正例、真反例、假反例的平均，再求查准率，查全率，F1，即为微查准率、微查全率、微F1 <br>
#### 3. ROC与AUC：<br>
ROC：Receiver Operating Characteristic，受试者工作特征<br>
AUC：对角线曲线，为随机猜测的基准线。
一般机器学习算法都是给出一个预测概率，概率大于阈值为正例，否则为反例。我们就可以根据概率将所有的预测结果降序排序，然后截取某个结果作为阈值。若更重视查准率，则阈值靠前；若更重视查全率，则阈值靠后。
##### 评判标准
真正例率：
<p>$$  正例预测为正例 \over 真正的正例总数  $$</p>
假正例率
<p>$$  反例预测为正例 \over 真正的反例总数  $$</p>
据此作出ROC与AUC曲线 <br>
评价：这种方法只考虑了比例，没考虑实际预测值的偏差（比如预测成0.9 和0.6效果一样，但是偏差比较大）。

#### 4. 代价敏感错误率与代价曲线：<br>
不同的预测错误会造成不同的后果，例如把患者诊断为健康人与把健康人诊断成患者的后果不同，所以对每种情况设定一个代价矩阵，然后使得总体代价最低。这种情况ROC曲线就无法满足要求，需要代价曲线。 <br>
考虑代价矩阵的ROC曲线所围成的面积即为总体代价，据此横轴为正例概率代价，纵轴为总体代价的归一化，作成代价曲线图。



## 参数求解 ##
### 最大似然 ###
概率最大
### 损失函数 ###
损失函数值最小
 
----------
## 多分类 ##
逻辑回归针对二分类问题，当解决多分类问题时，通常有两种方法：
##### 多次二分类
对每个类别都训练出一个二分类器（One-vs-all），这种方案对于每个类别不互斥的时候适用。
比如：每个用户会买哪个商品，对每种商品都算一个概率，大于阈值则买，商品直接并不互斥。
##### Softmax回归
类别直接互相排斥的情况，可以用Softmax回归。Softmax 回归是直接对逻辑回归在多分类的推广，相应的模型也可以叫做多元逻辑回归（Multinomial Logistic Regression）。模型通过 Softmax 函数来对概率建模，即求概率最大、损失最小的情况。总体代价函数考虑将样本分成每个类的损失只和，再考虑所有样本的损失只和，利用梯度下降、随机梯度下降等求解问题。



## 模型检验 ##
##### 假设检验
##### 交叉检验
##### McNemar检验（卡方检验）
##### Friedman检验 与 Nemenyi 后续检验



参考：https://tech.meituan.com/intro_to_logistic_regression.html